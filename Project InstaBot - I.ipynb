{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Login to your Instagram Handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1) Submit with sample username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "# Creating a web driver session\n",
    "\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# importing for exceptions\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome(executable_path = 'E:\\chromedriver')  # set the path here accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login() :\n",
    "    driver.get('https://www.instagram.com/') # visiting instagram\n",
    "    time.sleep(3)\n",
    "    user_name_text_box = driver.find_element_by_name('username') # finding text box for username\n",
    "    user_name_text_box.send_keys('SAMPLE USERNAME') # replace here with your username\n",
    "    pass_text_box = driver.find_element_by_name('password') # finding text box for password\n",
    "    pass_text_box.send_keys('SAMPLE PASSWORD') # provide here your password\n",
    "    driver.find_element_by_class_name('L3NKy').click()\n",
    "    time.sleep(3) \n",
    "    \n",
    "    # here, if the popup saying 'turn on notifications' is popped then it is handled\n",
    "    \n",
    "    try :\n",
    "        popup = driver.find_element_by_class_name('HoLwm')\n",
    "        if popup.is_enabled :\n",
    "            popup.click()\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling Function\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1) Note : Make sure to avoid printing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction for seaching for text box and seaching for the specific kwyword\n",
    "# This Function will be used in further Questions also\n",
    "\n",
    "def text_box(search_this):\n",
    "    text_box = driver.find_element_by_class_name('x3qfX') # finding text box using its class\n",
    "    text_box.clear() # clearing it so that if some other thing is written in it then it is removed first\n",
    "    text_box.send_keys(search_this) # searching for the keyword given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function searches for all the insta Handles displayed after typing 'food' and displays list of those handles\n",
    "# Locations and tags that comes on searching are handled i.e. are not displayed here.\n",
    "# Only instagram handles will be displayed.\n",
    "\n",
    "def food_insta_handles() :\n",
    "    text_box('food') # calling text_box function so that food is searched in search\n",
    "    time.sleep(4)\n",
    "    lst = driver.find_elements_by_class_name('yCE8d') # made list of all the elements in list\n",
    "    insta_handles = []\n",
    "\n",
    "    # done this so that only handles are displayed not tags and locations \n",
    "    \n",
    "    for i in lst:\n",
    "        if ('locations' not in i.get_attribute('href'))  and ('tags' not in i.get_attribute('href')) :\n",
    "            insta_handles.append(i)\n",
    "\n",
    "    for j in insta_handles :\n",
    "        print(j.find_element_by_xpath('div/div[2]/div/span').text) # printing text only here i.e only user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilsefoodie\n",
      "yourfoodlab\n",
      "food_lunatic\n",
      "food.swinger\n",
      "delhifoodguide\n",
      "tempting_thali\n",
      "food\n",
      "foodmaniacindia\n",
      "foodbloggersloop\n",
      "delhifoodnest\n",
      "food_junc\n",
      "street_food_chandigarh\n",
      "food_belly11\n",
      "foodrush.recipe\n",
      "ndtv_food\n",
      "foodie.__.world_\n",
      "delhifoodie\n",
      "foodbloggersnetwork\n",
      "delhifoodwalks\n",
      "food_physician\n",
      "buddies_and_foodies\n",
      "delhifoodprn\n",
      "meet_n_eat28\n",
      "food_gambler\n",
      "delhifoodrides\n",
      "food.ternion\n",
      "thisisdelhi\n",
      "street_food_jungle9\n",
      "foodiesince96\n",
      "tasteofgirl\n",
      "foodie_incarnate\n",
      "foodfirangi\n",
      "hmm_nikhil\n",
      "make_woke_foods\n",
      "foodfictionfashion\n",
      "food_e_ishq\n",
      "foodmani4c\n",
      "foodelhi\n",
      "foodisnirvana\n",
      "concentrate_on_food\n",
      "food.fascination_\n",
      "food__updates\n",
      "foodiliciousmoments\n",
      "foodiecouple_parvan\n",
      "foodyvid\n",
      "food_affair\n",
      "eatwithruchi\n",
      "_beauty_and_food_world\n"
     ]
    }
   ],
   "source": [
    "# calling finction\n",
    "\n",
    "food_insta_handles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Searching and Opening a profile using "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1)Open profile of “So Delhi” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for opening the profile given.\n",
    "# This function will be used extensively in further questions.\n",
    "\n",
    "def open_profile(profile_name) :\n",
    "    text_box(profile_name) # calling text_box function to search for given keyword\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_class_name('yCE8d').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# searching and opening 'So Delhi' profile.\n",
    "# ques 3.1)\n",
    "\n",
    "open_profile('So Delhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Follow/Unfollow given handle - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1) Open the Instagram Handle of “So Delhi”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2) Start following it. Print a message if you are already following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3) After following, unfollow the instagram handle. Print a message if you have already unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function to follow So Delhi's page and if already following print msg\n",
    "\n",
    "def follow():\n",
    "    if driver.find_element_by_class_name('_6VtSN').text == 'Follow' : # condn to check if already following or not\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_class_name('_6VtSN').click() # following it\n",
    "    else:\n",
    "        print('You are already following')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following So Delhi and printing msg if already following\n",
    "\n",
    "follow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to un-follow So Delhi's page and if already un-following print msg\n",
    "\n",
    "def UnFollow():\n",
    "    if driver.find_element_by_class_name('_6VtSN').text == 'Follow' : # condition to check if already following or not\n",
    "        print('You are already NOT following it')\n",
    "    else:\n",
    "        driver.find_element_by_class_name('_6VtSN').click() # opening unfollow button\n",
    "        time.sleep(3)\n",
    "        a = driver.find_element_by_class_name('-Cab_')\n",
    "        time.sleep(3)\n",
    "        a.click() # unfollowing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-following So Delhi and printing msg if already NOT following \n",
    "\n",
    "UnFollow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Like/Unlike posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1) Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to like the top 30 posts of given profile\n",
    "\n",
    "\"\"\"\"\"\n",
    "In this function i have first scrolled the page to 6000 pixels as many times more than 30 posts are not loaded.\n",
    "then i have found all the posts on the page and then after that took top 30 posts and liked them ,\n",
    "and if they are liked already then i have printed the message for same posts.\n",
    "\n",
    "\"\"\"\"\"\n",
    "\n",
    "def Like_post(profile) :\n",
    "    driver.get('https://www.instagram.com/')\n",
    "    open_profile(profile) # calling function to open given profile\n",
    "    time.sleep(4)\n",
    "    driver.maximize_window() # maximizing window so more posts can be loaded\n",
    "    driver.execute_script('window.scrollTo(0, 6000);') # Scrolling to 6000 pixels\n",
    "    time.sleep(3)\n",
    "    posts = driver.find_elements_by_class_name('v1Nh3') # finding all posts on page\n",
    "    for i in range(30):\n",
    "        posts[i].click() # clicking on each post\n",
    "        time.sleep(2)\n",
    "        like = driver.find_element_by_css_selector('span.fr66n>button') # finding like button\n",
    "        if like.get_attribute('aria-label') == 'Like' : # checking condn if already liked or not\n",
    "            like.click()\n",
    "        else :\n",
    "            print('You have already liked post number', i+1)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_class_name('yiMZG').click()  # clickeng on cross button\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have already liked post number 1\n",
      "You have already liked post number 2\n",
      "You have already liked post number 3\n",
      "You have already liked post number 4\n",
      "You have already liked post number 5\n",
      "You have already liked post number 6\n",
      "You have already liked post number 7\n",
      "You have already liked post number 8\n",
      "You have already liked post number 9\n",
      "You have already liked post number 10\n",
      "You have already liked post number 11\n",
      "You have already liked post number 12\n",
      "You have already liked post number 13\n",
      "You have already liked post number 14\n",
      "You have already liked post number 15\n",
      "You have already liked post number 16\n",
      "You have already liked post number 17\n",
      "You have already liked post number 18\n",
      "You have already liked post number 19\n",
      "You have already liked post number 20\n",
      "You have already liked post number 21\n",
      "You have already liked post number 22\n",
      "You have already liked post number 23\n",
      "You have already liked post number 24\n",
      "You have already liked post number 25\n",
      "You have already liked post number 26\n",
      "You have already liked post number 27\n",
      "You have already liked post number 28\n",
      "You have already liked post number 29\n",
      "You have already liked post number 30\n"
     ]
    }
   ],
   "source": [
    "# printing about only those posts which are already liked \n",
    "\n",
    "Like_post('dilsefoodie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2) Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Unlike the top 30 posts of given profile\n",
    "\n",
    "\"\"\"\"\"\n",
    "In this function i have first scrolled the page to 6000 pixels as many times more than 30 posts are not loaded.\n",
    "then i have found all the posts on the page and then after that took top 30 posts and Unliked them ,\n",
    "and if they are Unliked already then i have printed the message for same posts.\n",
    "\n",
    "\"\"\"\"\"\n",
    "def UnLike_post(profile) :\n",
    "    driver.get('https://www.instagram.com/')\n",
    "    time.sleep(4)\n",
    "    open_profile(profile) # calling func to open given profile\n",
    "    time.sleep(4)\n",
    "    driver.maximize_window() # maximizing window so more posts can be loaded\n",
    "    driver.execute_script('window.scrollTo(0, 6000);') # Scrolling to 6000 pixels\n",
    "    time.sleep(3)\n",
    "    posts = driver.find_elements_by_class_name('v1Nh3')\n",
    "    for i in range(30):\n",
    "        posts[i].click()\n",
    "        time.sleep(2)\n",
    "        like = driver.find_element_by_css_selector('span.fr66n>button') # finding Unlike button\n",
    "        if like.get_attribute('aria-label') == 'Unlike' : # checking condn if already Unliked or not\n",
    "            like.click()\n",
    "        else :\n",
    "            print('You have already Unliked post number', i+1)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_class_name('yiMZG').click()\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have already Unliked post number 1\n",
      "You have already Unliked post number 2\n",
      "You have already Unliked post number 3\n",
      "You have already Unliked post number 4\n",
      "You have already Unliked post number 5\n",
      "You have already Unliked post number 6\n",
      "You have already Unliked post number 7\n",
      "You have already Unliked post number 8\n",
      "You have already Unliked post number 9\n",
      "You have already Unliked post number 10\n",
      "You have already Unliked post number 11\n",
      "You have already Unliked post number 12\n",
      "You have already Unliked post number 13\n",
      "You have already Unliked post number 14\n",
      "You have already Unliked post number 15\n",
      "You have already Unliked post number 16\n",
      "You have already Unliked post number 17\n",
      "You have already Unliked post number 18\n",
      "You have already Unliked post number 19\n",
      "You have already Unliked post number 20\n",
      "You have already Unliked post number 21\n",
      "You have already Unliked post number 22\n",
      "You have already Unliked post number 23\n",
      "You have already Unliked post number 24\n",
      "You have already Unliked post number 25\n",
      "You have already Unliked post number 26\n",
      "You have already Unliked post number 27\n",
      "You have already Unliked post number 28\n",
      "You have already Unliked post number 29\n",
      "You have already Unliked post number 30\n"
     ]
    }
   ],
   "source": [
    "# printing about only those posts which are already Unliked \n",
    "\n",
    "UnLike_post('dilsefoodie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Extract list of followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1) Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Here in this question i have first created a function to get 500 followers of a instagram handle which needs to be passed\n",
    "So, first i have visited the given page and then scrolled till 500 followers are not loaded on page .\n",
    "then extracted those followers.\n",
    "\n",
    "\"\"\"\"\"\n",
    "def user_names(profile) :\n",
    "    driver.get('https://www.instagram.com/')\n",
    "\n",
    "    open_profile(profile) # calling function to open given profile\n",
    "    time.sleep(4)\n",
    "    driver.find_elements_by_class_name('Y8-fY')[1].click() # opening followers section\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # applying infinite loop just with condn i.e till 500 followers\n",
    "    \n",
    "    current_height = driver.execute_script('return document.getElementsByClassName(\"isgrP\")[0].scrollHeight;') \n",
    "    followers = driver.find_elements_by_class_name('FPmhX') # extracting current followers\n",
    "\n",
    "    while len(followers) <= 500 : # condn\n",
    "        driver.execute_script('document.getElementsByClassName(\"isgrP\")[0].scrollTo(0, arguments[0]);', current_height)\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script('return document.getElementsByClassName(\"isgrP\")[0].scrollHeight;')\n",
    "        current_height = new_height\n",
    "        followers = driver.find_elements_by_class_name('FPmhX') # extracting all followers\n",
    "        \n",
    "    return followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to extracting only 500 followers in a set as in previous function there may be more than 500 followers as \n",
    "# the page loaded may have more than 500 followers\n",
    "\n",
    "def Food_talk_followers(profile) :\n",
    "    followers_ = user_names(profile)\n",
    "    Food_Talk_Followers = set()\n",
    "    \n",
    "    # extracting followers in a set\n",
    "    \n",
    "    for i in range(500):\n",
    "        Food_Talk_Followers.add(followers_[i].get_attribute('title')) # taking only title attr i.e. only usernames\n",
    "    \n",
    "    return Food_Talk_Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amritaagarwalla\n",
      "syedakiranali75\n",
      "_khaadya_padarth\n",
      "apna_chulha09\n",
      "krisvirshak\n",
      "anureet3421\n",
      "adil7_a7\n",
      "rohit.chhabaria.39\n",
      "aravinds16\n",
      "food_.laboratory\n",
      "rohitjeswani7\n",
      "darkness_exe11\n",
      "okheaprints\n",
      "ernestomaostalinhitler\n",
      "mkeishing\n",
      "foodstationbylalli\n",
      "_shraddha___23\n",
      "agrawalr1300\n",
      "kolik1086\n",
      "raashichavan\n",
      "mukeshkuswahamukes\n",
      "mindsinatelier\n",
      "yumiee_tastieee\n",
      "akshataa_patill\n",
      "priyanshipal_\n",
      "easy_vegetarian_recipes\n",
      "foodarchivers\n",
      "emanuelezangari_bartender\n",
      "indranild007\n",
      "homeandkitchentour\n",
      "imaginating_eyes\n",
      "_samruddhi_29\n",
      "kuldeep.kc121\n",
      "mumbaimaveric\n",
      "sojadarsh\n",
      "hidz1680\n",
      "kalia4141\n",
      "bani_kl\n",
      "vijan_08\n",
      "mayank_arya2597\n",
      "fitness.workout.diet\n",
      "shilpa_chandran1.0\n",
      "divyamishra94\n",
      "santosh.murlidharghodke_dudhad\n",
      "agrihalfland\n",
      "kunalsain613\n",
      "rivu1017\n",
      "qu33n_68\n",
      "harman_cooking\n",
      "chandiprasadmallik\n",
      "orgchoin\n",
      "atifsiddiqi\n",
      "akashbidlan8\n",
      "foodlove_87\n",
      "vishaldogra1990\n",
      "cafelogy2\n",
      "anjali.curates\n",
      "matka_kilo\n",
      "balaramdey\n",
      "ankur._gogoi\n",
      "cutie_pie_dav_lin\n",
      "ig_gyanibhaiya\n",
      "shim.a131\n",
      "veenit_rao\n",
      "naashtotime\n",
      "ayush.srivastava.545\n",
      "mr_baba_21\n",
      "_.yohiyouhoes._\n",
      "food.is.my.valentine\n",
      "james_d_e_p_e_n\n",
      "sachinbansal211\n",
      "pooja_duggar\n",
      "atul_bakery\n",
      "dusky.charm._\n",
      "aditiigarg\n",
      "andi_panyiwi\n",
      "itskushika\n",
      "kalpladhani\n",
      "vikashvirk4088\n",
      "avantikalovesunil\n",
      "ambika_bansal26\n",
      "dripping_drizzels\n",
      "venom_0397\n",
      "nitisshhh__\n",
      "abhishek_sharma_0008\n",
      "whiskmixstir\n",
      "mayuhats\n",
      "cook_with_mini_ideas\n",
      "k._bhavika\n",
      "mansi.ar\n",
      "chaudhary_renu_\n",
      "sivvran_raj\n",
      "anishakatyal\n",
      "visingh8783\n",
      "_just__eat__it_\n",
      "poonamjoshi386\n",
      "simran___sagar\n",
      "noumaan_bad_boy_77\n",
      "i_m_loveing_aaru_\n",
      "ishefali_gupta\n",
      "the_rasoi_basics\n",
      "aakritidobhal\n",
      "stringentlife\n",
      "pangatchawla\n",
      "lost_hearted_9749\n",
      "gosavi4643\n",
      "sudeshna_dey05\n",
      "saikrishna_gunni\n",
      "a27_shutterbug\n",
      "sahidhussain86\n",
      "bharat_mlh\n",
      "trivendrakumar.deaf\n",
      "crazy_tummy\n",
      "ravi_gadhvi_official\n",
      "_pastimestories\n",
      "foodie_arnab\n",
      "maheshchand5680\n",
      "explore.saurabh\n",
      "shiva___mogili\n",
      "kamnagarg705\n",
      "sidd0306\n",
      "niha_begum_6\n",
      "shruti._.kansal\n",
      "princekhara665\n",
      "littlebitofsoulitude\n",
      "calcutta_8\n",
      "phalguni_s\n",
      "whats__on_my_plate\n",
      "regirtr\n",
      "mnsgourmetaffairs\n",
      "i_am_rajput0\n",
      "archiebags_\n",
      "vandnachauhan7__\n",
      "i_am_indian_0k\n",
      "flavorsofhummus\n",
      "teamelite95\n",
      "srinath8_m\n",
      "chandan_hiten\n",
      "israth2050\n",
      "pearlfashionsindia\n",
      "sahilgupta010\n",
      "jr.ankitbodh\n",
      "sharan_soorly\n",
      "kediasanjiv\n",
      "ku.suma8409\n",
      "kanwal_arora\n",
      "swayam_2001\n",
      "rishi.ratnakar.54\n",
      "the_kitchensoul\n",
      "chintan_prajapati\n",
      "fusionfood259\n",
      "kaushikfilms\n",
      "momsmagic6555\n",
      "rohit.kadam143\n",
      "sapathan25\n",
      "sweetsurprise2930\n",
      "sanskrutigawali6494\n",
      "ya_man.19\n",
      "shorash0sido\n",
      "dikshachandra27\n",
      "root2_ham\n",
      "mahii_yadav_____420\n",
      "ajourneytotell_\n",
      "parmeetarneja\n",
      "saroj.agrawal.3990\n",
      "vivek.maheshwari1012\n",
      "techknowlogy_updates\n",
      "_india.fas.hionheritage_\n",
      "_shaktikbanerjee_\n",
      "imilyahi\n",
      "_chefsplate14\n",
      "mommytimesblog\n",
      "dateman.dryfruits\n",
      "hars_h9700\n",
      "sonalibehl_27\n",
      "qualitydryfruits\n",
      "shweta373\n",
      "_khushi2512\n",
      "yugininteriordesigns\n",
      "ni_lam_45\n",
      "nchltoni\n",
      "cafes_story\n",
      "anamj03\n",
      "rafeyather\n",
      "adhwait_7777\n",
      "dhe196\n",
      "creativenaaaz\n",
      "amafhh_diets\n",
      "chef_rohitrana\n",
      "simuuchokolades\n",
      "maltandsalt1\n",
      "milkbajar\n",
      "aman_kochar.ak\n",
      "foodiethefoodlover\n",
      "s_m_i_t_3_3_3\n",
      "_n_ia_\n",
      "refectionsthejuicebar\n",
      "syedzafar.it\n",
      "tantarykasir\n",
      "ridhimac.narang\n",
      "varunabbi\n",
      "being_a_bong\n",
      "marvelinsta2020\n",
      "foodies_favorites\n",
      "rohit.shetty05\n",
      "jitendrapatel6455\n",
      "thetummylove\n",
      "meenalkhandelwal\n",
      "mummies_savory_delights14\n",
      "ayush_bhatnagar95\n",
      "shiva.lee007\n",
      "anirudhyaroy1\n",
      "soumyadeep460\n",
      "food_foodie30\n",
      "eatsleeprunglow\n",
      "ameya.kotian\n",
      "ram_sir_karan_n_group\n",
      "shubh_9\n",
      "sibanisaxena\n",
      "mdbabulhossain.bd\n",
      "kaysgetaway\n",
      "studiobrickandnest\n",
      "snackstory_official\n",
      "prashanttalawar8\n",
      "mouth_freshner.mumbai\n",
      "good_food_brings_good_mood\n",
      "good_food_70\n",
      "bhukkad_sheth\n",
      "malvika_keswani\n",
      "yadav_sarkar13\n",
      "siddhali.a.k\n",
      "team_with_laugh\n",
      "creamy_n_licious\n",
      "wokofhappiness\n",
      "aww__licious\n",
      "fiza__9900\n",
      "local_ka_traveller\n",
      "food_word_kp\n",
      "smak7262\n",
      "babbynsjournal\n",
      "ashiq_ali1\n",
      "_bharath_ennum_naan\n",
      "huge_collection_\n",
      "ianamikabanerjee\n",
      "simply_unique_1\n",
      "zayka_darbaar\n",
      "akhil_cam\n",
      "ud_prem_\n",
      "chinmaymittal1978\n",
      "kiranshah2190\n",
      "food_from_khatyn\n",
      "mukeshyadav919482\n",
      "rashmi_vijayendran\n",
      "simran.jhaveriii\n",
      "its_ashman.__\n",
      "chaseme73\n",
      "prajnay.darkins\n",
      "maarzina_poly\n",
      "sachinjaat5948\n",
      "drift_to_joy\n",
      "an_uj6496\n",
      "bhavipandit\n",
      "aftabalam488\n",
      "gargikabi\n",
      "ohana_enterprise_\n",
      "babes_557\n",
      "amrutaginde\n",
      "neha___honey_miss\n",
      "dreamprintmedia\n",
      "my_mirchi_masala\n",
      "sanjana_6.97\n",
      "sudeshna_mukhopadhyay\n",
      "bhaavi.agrawal\n",
      "explorer_pre\n",
      "pratiek7776\n",
      "sarcasticbaniya00\n",
      "kkrishna_5075\n",
      "pinkyairen\n",
      "shantin.orickompil\n",
      "aagri16\n",
      "azhariseafood\n",
      "aaliyaruku\n",
      "_rasmalai\n",
      "delicacy_at_its_best\n",
      "mayra_couture\n",
      "dash.bhagyashree\n",
      "yumniastic_india\n",
      "ila.hira\n",
      "shellyfoodspot\n",
      "firangfood\n",
      "sarangheritage\n",
      "bannorajasthani\n",
      "mr.soni1996\n",
      "_.impriyanka\n",
      "pallavi.chowdhury092018\n",
      "amreenoffscreen\n",
      "madovershawls\n",
      "awesome_aman6786\n",
      "cook_wid_pooh\n",
      "swatisa\n",
      "anoopetamilindia\n",
      "vikram.kumbhar.984\n",
      "adashandasplash\n",
      "satyajeetrohans\n",
      "_preeran.srishmeer_\n",
      "the_absolut_malan\n",
      "explore_world_universe\n",
      "umesh_vasava_59\n",
      "sachiincy\n",
      "mraqram8319\n",
      "life_is_full_of_surprises_15_\n",
      "raj_rinks\n",
      "food_freaked\n",
      "hayatkhan6334\n",
      "sata_vishab\n",
      "lakhan.d_\n",
      "jigyasaaroramehra\n",
      "anileo1794\n",
      "mvk.group\n",
      "peyush_baranwal\n",
      "itspranavisuals\n",
      "moon.coding\n",
      "mavr.ick15\n",
      "nikki.nikesh\n",
      "aryanchandel89\n",
      "sohamjadhav__15\n",
      "mrana27\n",
      "ak.ee.19\n",
      "_hate_guy\n",
      "blissfulbhilai\n",
      "krish__2019\n",
      "gaurav554sharma\n",
      "jituemmii\n",
      "manisha_sardiwal\n",
      "imsoniadubey\n",
      "shrieeharipakoda2020\n",
      "usman_gani.khatri\n",
      "sureshchoudharys4128\n",
      "gurgaonfoodcircle\n",
      "nishant__sinngh\n",
      "03hema\n",
      "goutambar50\n",
      "vainateymg\n",
      "celebritymyfavourite\n",
      "fez.k\n",
      "_anil_2423\n",
      "travelanna.ta\n",
      "__heri_prottar_333__\n",
      "asciansays\n",
      "pawan.1986\n",
      "tejas_patil_1877\n",
      "gauravbaba_1331_\n",
      "gharkakhaana304\n",
      "ritu.vohra.0622\n",
      "vanashreeyoga\n",
      "upasanayadav2912\n",
      "food.ie154\n",
      "insta_nique\n",
      "aajkajevan\n",
      "agricious.sumitbishnoi\n",
      "midnight_quirky\n",
      "herecomesjony\n",
      "guptaarpita04\n",
      "brownieboutiquelk\n",
      "mv929845\n",
      "zikra1989\n",
      "twincityflavours\n",
      "afterhours_sweettoothfix\n",
      "biswajitsamantaray\n",
      "foodblogger_ashishkatiyar\n",
      "ayushiagarwal_fashion\n",
      "aj_arbaj_k99\n",
      "maverickamit\n",
      "balas_krishnas\n",
      "rajj.dilip\n",
      "ronakmalviya25\n",
      "siva_24_29\n",
      "mohammadibad15\n",
      "harikateja\n",
      "funandfoodwithsourya\n",
      "vidhu.gemini\n",
      "visha_l8688\n",
      "jyotsna_d_nanda\n",
      "taste_o_mania_\n",
      "chavan_reshma\n",
      "rock_jay_001\n",
      "dhairyapatelp\n",
      "hr.7485\n",
      "__cricket__lover__\n",
      "bongbongfoods\n",
      "fun_en_shake\n",
      "2mustvisit\n",
      "100rab_agrawal\n",
      "theleeskitchen\n",
      "amanshah3232\n",
      "thehungryhindustani\n",
      "myclickway1\n",
      "foode_mon\n",
      "senthilre\n",
      "vinay_ranjan_das7\n",
      "chakh_kar_dekho\n",
      "blueplateindia\n",
      "amirakib4\n",
      "phalsabji\n",
      "taha_dix_neuf_197\n",
      "sex_toys_toyss\n",
      "fashion__cuisine\n",
      "piya7546\n",
      "friedisthan\n",
      "nashra98760\n",
      "_khageshsinghrajput_\n",
      "__bad_caption________\n",
      "its_dad07\n",
      "di.mple31601\n",
      "prerna_chadha\n",
      "akis_kitchen2020\n",
      "dipaligaw\n",
      "__n.u.b__x.8\n",
      "chawlaannu\n",
      "sudeepta_bora\n",
      "ruchisingh47\n",
      "vijaysinh126\n",
      "crazy_flavourful_and_frenzy\n",
      "creating.my.vibe\n",
      "sharduldevsingh\n",
      "kusumasherapur\n",
      "arsheen_384\n",
      "sap_marodi\n",
      "lusia_ann\n",
      "binging_xo\n",
      "kamal.5816\n",
      "createcultivate.13\n",
      "khaana_badosh004\n",
      "_aashii_pvt__\n",
      "the_weekendmixologist\n",
      "blogwithananya\n",
      "chanda_kanu\n",
      "adi.dooshima\n",
      "eat_tummyfit\n",
      "brandonstarling\n",
      "passionfor_dreams\n",
      "yashvardhansr16\n",
      "palakkadam9252\n",
      "ihemantthakur\n",
      "miheerdhamankar\n",
      "mrsunilsharma9211\n",
      "ashah_8438\n",
      "sonali._.barahate\n",
      "way2burger\n",
      "simran_talreja9\n",
      "aarnav_das\n",
      "saira.yusuf.7\n",
      "anujj.kushwah\n",
      "mafiaa9962\n",
      "jinal__suthar\n",
      "grainola.in\n",
      "_chefonstreet\n",
      "vipul_aggarwal49\n",
      "minugeorge19\n",
      "radhacookingclasses\n",
      "megha.wadkar\n",
      "guhnpunjwani\n",
      "anurag.tripathi.5243\n",
      "foodslockerinfo\n",
      "yum._in_.tum\n",
      "mentorica_institute\n",
      "quarantinedayss_2020\n",
      "erikaann810\n",
      "____wittypunjabiwedding___\n",
      "foodtastic.mumbai\n",
      "rahulsatija29\n",
      "manuela____food\n",
      "pramod_pawar_mh_12\n",
      "dr.anoshfiaz\n",
      "yash_pal_singh_chundawat\n",
      "ar_ya7156\n",
      "rrahulkumaar2006\n",
      "annie_pubgm\n",
      "bhukkadnukkad_\n",
      "theinquisitiveidiot\n",
      "ganesh.subramani\n",
      "fashplatter\n",
      "radhikasharma27\n",
      "abheejeetahuja\n",
      "mujawar5757\n",
      "govindkharol_33\n",
      "reyaan_khuranaa\n",
      "sukh_chander\n",
      "prasannakumar.d.581\n",
      "vivek_parmar_5055\n",
      "saroal123\n",
      "homebaker_19\n",
      "naveenkhavre\n",
      "rathiji007\n",
      "sukuralig\n",
      "al_bismillah_biriyani\n",
      "niraj___king\n",
      "mail2home_cooking\n",
      "shivagill_moga\n",
      "nikumbhprasad24\n"
     ]
    }
   ],
   "source": [
    "# calling function for foodtalkindia and printing the set\n",
    "\n",
    "Food_Talk_India_Followers = Food_talk_followers('foodtalkindia')\n",
    "\n",
    "for i in Food_Talk_India_Followers :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to extracting only 500 followers in a set as in previous function there may be more than 500 followers as \n",
    "# the page loaded may have more than 500 followers\n",
    "\n",
    "def So_Delhi_followers(profile) :\n",
    "    followers1 = user_names(profile)\n",
    "    time.sleep(6)\n",
    "    So_Delhi_Followers = set()\n",
    "    \n",
    "    # extracting followers in a set\n",
    "    \n",
    "    for i in range(500):\n",
    "        So_Delhi_Followers.add(followers1[i].get_attribute('title')) # taking only title attr i.e. only usernames\n",
    "    \n",
    "    return So_Delhi_Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momo_tivated\n",
      "chhabra2601\n",
      "deveshsapra84\n",
      "fromnewdelhi_withlove\n",
      "poonam.haryani\n",
      "vanshjairath\n",
      "garima3804\n",
      "garm_entshopping\n",
      "_pallavi_dubey_\n",
      "shruti_sharma_12\n",
      "sam_ali.15\n",
      "syed_zartasha_zainab\n",
      "roochs_\n",
      "vishalvishal3143\n",
      "deepak.sainimbd420420\n",
      "syed_arshann_ali\n",
      "iam_shail_soni\n",
      "hardik.goel\n",
      "im_suyal\n",
      "nad_dishes_\n",
      "shubhamsharma.bly\n",
      "buceador__halcon\n",
      "_ayush_2497\n",
      "uday_singh2480\n",
      "puneet2400\n",
      "explore.create.with.sid\n",
      "manushvi\n",
      "rinkuuu.21\n",
      "sauteandtadka\n",
      "thoughts.inked\n",
      "imaginating_eyes\n",
      "akki_agendre\n",
      "believer8905\n",
      "priyankakaushal_14\n",
      "mohd2974\n",
      "elsaksham\n",
      "hrishi.bhatnagar\n",
      "nehae4f\n",
      "piyachaudhary123\n",
      "the_creativity_boxx\n",
      "sriishhti\n",
      "trzah\n",
      "rajat.2606\n",
      "gudiyakumari5050\n",
      "shihindu.devi.35\n",
      "_memoo.__\n",
      "_navya.jha_\n",
      "tanisha_zulfi\n",
      "confuse_aatmaa\n",
      "_manit_kaur\n",
      "mohitmehta28\n",
      "ig.vimla\n",
      "interior_work1784\n",
      "ajay_pndit_143\n",
      "s_luv143\n",
      "club__style_\n",
      "____akriti_____\n",
      "mehrotrasakshii\n",
      "amityadavx\n",
      "deliciousrescue\n",
      "crazy_millennial\n",
      "priyasadh09\n",
      "kaaransharmaksh45\n",
      "divyaroraa03\n",
      "maryamzakarya9259\n",
      "ramanjot27\n",
      "meghakumari2046\n",
      "arnab863729\n",
      "sona_kaur_dhariwal\n",
      "kb_khevu\n",
      "sanjubidhuri\n",
      "merakiiarthouse\n",
      "sudher30_cafe_xero_degrres\n",
      "rocckypatel007\n",
      "flowerquotes.__\n",
      "kohli.ishant199\n",
      "sihra_sensei\n",
      "hunarrx\n",
      "hungry._.again\n",
      "namandeep_bhullar\n",
      "01sakshi__\n",
      "akansha_thecreativer\n",
      "gurisingh.24\n",
      "pranavbakhshi\n",
      "tilok.prajapat.146\n",
      "ishi_garg17\n",
      "d.shivank\n",
      "iamto_busy22\n",
      "malaymridul\n",
      "arvinder.grover.30\n",
      "ziya_718\n",
      "mohit.sharma1991\n",
      "dachen_710\n",
      "officialpeopleofcalcutta\n",
      "itzz__a.kayy\n",
      "aladdin.safeandsane\n",
      "bbfood_hub\n",
      "electricenglish\n",
      "pawan_s_samant\n",
      "themukulchugh\n",
      "shristishah780_\n",
      "dapun29\n",
      "_lucky.paswan_\n",
      "sivvran_raj\n",
      "cibo_rk\n",
      "shubham.sr4\n",
      "meghann.sandhu\n",
      "hemang_khandelwal\n",
      "m.y.s.p.a.ce\n",
      "simranjit.saluja\n",
      "_vijita_\n",
      "suuaanniii\n",
      "neeti_garg\n",
      "soumipalglitters\n",
      "bindiya_ahuja\n",
      "greeeetings7416\n",
      "rahul_kesar\n",
      "to_yash.singh\n",
      "alo_neboy1999\n",
      "canvassinnova\n",
      "gauravkwatra\n",
      "be_deep_\n",
      "nehagakkar\n",
      "khatrejavanya\n",
      "shivajewellers7\n",
      "foodie_arnab\n",
      "mohdrizwan09874\n",
      "vikash_pune\n",
      "thefoodiestaaz\n",
      "gurharman8\n",
      "shahid__afreed97\n",
      "_shruti_1114\n",
      "janki15690\n",
      "vivek.9184\n",
      "eastdelhiwalaladka\n",
      "rajendra199715\n",
      "srishti_loomba\n",
      "sonyrajput17\n",
      "nchimna\n",
      "chan.nelise\n",
      "mariapolo_54\n",
      "desai.roma96\n",
      "flavorsofhummus\n",
      "ppreetisingh\n",
      "shiz.roshani\n",
      "bhu_takta_chik\n",
      "houseofhermosaa\n",
      "jyotibala9072\n",
      "su_mit1341\n",
      "informando_sinais_do_fim\n",
      "cr42sumit\n",
      "zayrishsiddique\n",
      "babaji5722\n",
      "x.aanchal\n",
      "goofywanderer_\n",
      "gmd00734\n",
      "monikapaul05\n",
      "basmah_farheen\n",
      "asthana2626\n",
      "shivi_jammu_1993\n",
      "parth_patel897\n",
      "food.ie27\n",
      "vishalgaykvd\n",
      "vidu_bhardwaj\n",
      "mohammadnadir99\n",
      "fla.voursofindia\n",
      "mathur.sahil1995\n",
      "_c_f_13021996\n",
      "ashwani_apjs\n",
      "kartik._.911\n",
      "_sheena.bhatia_\n",
      "kumarpramod43736\n",
      "they_just_said\n",
      "yamica_chopra\n",
      "karan_chugh54\n",
      "idfcare1\n",
      "ishan_rai_\n",
      "mohitmishra1808\n",
      "meghamorphic\n",
      "vaishali_shaktawat\n",
      "im_rishutosh\n",
      "niharikaa.kumar\n",
      "anugya._.singh\n",
      "barupalhitesh\n",
      "rohit_chawla45\n",
      "sheetal_2096\n",
      "nishtha__chopra\n",
      "tanyyj_11\n",
      "subarna__chaki\n",
      "talim_model\n",
      "pandit_hemu_bhardwaj_0007\n",
      "jaybhavaniggn\n",
      "shawron_7\n",
      "ilessis18\n",
      "_aryan_dev\n",
      "ankitsharm55\n",
      "saloni.s.587\n",
      "tamanna____25\n",
      "hurprise_event\n",
      "_chugh.sahab_\n",
      "anshika.ohri\n",
      "gauravpandey0009\n",
      "s_m_i_t_3_3_3\n",
      "manoj.garg1\n",
      "srikantchandran__\n",
      "wanderersoul_scope\n",
      "anantdikshit\n",
      "rashi.sharma19021\n",
      "ideepakrajput\n",
      "sameersalmani124\n",
      "ashutosh_gurjar92\n",
      "thenailstudio.and.academy\n",
      "chilly_flakes16\n",
      "___nehaa08\n",
      "taxincanada\n",
      "komal_.65\n",
      "mallikaa_kapoor\n",
      "iloveloveskies\n",
      "rayankdutt\n",
      "lifestylealteration\n",
      "shiivaniyadav\n",
      "ananya_shivnath\n",
      "muskanmakhija11\n",
      "itanyagupta\n",
      "raisakatyal\n",
      "sahilhussain143\n",
      "siddharth_g\n",
      "thedream807catcher\n",
      "haseenkhan691\n",
      "divyasingh_artistry\n",
      "gauravjatwani74\n",
      "wild._.soul\n",
      "m_e_s_s_e_d_up\n",
      "lovewrites11\n",
      "prachi_agg2504\n",
      "aadyagarg42\n",
      "kuvam_sehgal\n",
      "happy.parjapati786\n",
      "k_toqir_\n",
      "_lucky__gem_\n",
      "ajay.xret\n",
      "ruatkimi_04\n",
      "meemzthe21\n",
      "aditi.o1\n",
      "uglydumbfuck\n",
      "devartika\n",
      "gauravjain96\n",
      "the_styl_mermaid\n",
      "vkohli13\n",
      "shimayasodhi2025\n",
      "anjuu__zzz\n",
      "kevasiya.in\n",
      "__maanasee__\n",
      "vr_maniya01\n",
      "shuk_rana_guruji\n",
      "naduuu_nadaa\n",
      "wardrobiest\n",
      "shikha_sheoran\n",
      "company.tat.bizinac01234\n",
      "weird_vibes_wv\n",
      "jiyoraw.cold.pressed.oil\n",
      "ishangupta2004\n",
      "kreetikasmadan\n",
      "nitesh8393kumar\n",
      "bassi_geetika\n",
      "vinaytolia\n",
      "sardarrizwan037\n",
      "defaultervickypandit\n",
      "_senil_416\n",
      "swaahti\n",
      "poornima_sharma2001\n",
      "insoumynia\n",
      "dev.editography\n",
      "khyatiy\n",
      "ggrishikaa\n",
      "ravi_bairwa\n",
      "love_is_fuck_506\n",
      "_mis_arora22\n",
      "anujuttam1\n",
      "chanchalpal___\n",
      "nidhipal116\n",
      "vishal_editzzz\n",
      "sparkmysoul__kk\n",
      "shreyas_pannase\n",
      "still.hungry_\n",
      "door.ba\n",
      "ashrikabehl\n",
      "anshu9709090\n",
      "official_k_soni\n",
      "shashank_mishra4\n",
      "neeta.sahajwani\n",
      "feeling_remain_untouch\n",
      "sonaliexclusive\n",
      "rollingpencil20\n",
      "gunn0017\n",
      "lipikaaray\n",
      "nimi2107\n",
      "crushhonworld\n",
      "ishalteration\n",
      "adashandasplash\n",
      "_qafirana__\n",
      "pihu_sharma9958\n",
      "ladyfingernailsspavasantkunj\n",
      "nature_photos_greenary\n",
      "guglis_puff\n",
      "junedrehman30\n",
      "newparadisepizza\n",
      "par.dhan_\n",
      "sakshimohan\n",
      "sannchitaaa_\n",
      "sanjeevsingh1826\n",
      "shoaib.sultan_\n",
      "dtimetraveller.photography\n",
      "garlic_naaan\n",
      "shrutijain_2504\n",
      "raj_rinks\n",
      "geetanjali.khanna\n",
      "enna_love__\n",
      "missprernarora\n",
      "ssaurabh.ssingh\n",
      "lpvikrant\n",
      "faizulhaque9\n",
      "chopra7814\n",
      "nneel.datta\n",
      "seventeen_ly\n",
      "snehaa_134\n",
      "kamalkishorepahadiya.1984\n",
      "tejal_2311\n",
      "jhagula\n",
      "dineshsingh45649\n",
      "foodieedelhite\n",
      "mansirocks22\n",
      "yash.bararia\n",
      "_mitushihanduja_\n",
      "secre_ts4success\n",
      "_sun._.shine_79\n",
      "knowabhishekrai\n",
      "meuiyagi\n",
      "gargrajat04\n",
      "piyush.aggarwal10\n",
      "teewentpvt\n",
      "mylens_stories\n",
      "shruti.pasrija\n",
      "sanjiivkumar\n",
      "arya_value_bazaar\n",
      "hgulfishan\n",
      "kanishka_g07\n",
      "siddharthjain1181\n",
      "mehendi_by_farhat\n",
      "______oyesingh_____\n",
      "v_anushka\n",
      "kasaudhan9999\n",
      "the_branded_devil\n",
      "followrealindia\n",
      "sundramshahi96\n",
      "tanisha.kalra\n",
      "kupwaraphotographyclub\n",
      "cafedosti.delhi\n",
      "asciansays\n",
      "monica_gupta__\n",
      "amitranaaaa\n",
      "_geetikaakiteeg_\n",
      "ekta_kalra_sikri\n",
      "sonal.vijay10\n",
      "sakshii_1302\n",
      "angryverma\n",
      "seria.viena\n",
      "anjalighangas\n",
      "ar_unkumar2581\n",
      "bisht.02\n",
      "official_pandat_05207\n",
      "singh_digvijay20\n",
      "nomadic.zone\n",
      "rg90.rishabh\n",
      "keen_travellers\n",
      "chhotu3311\n",
      "rud_fzn\n",
      "kareem.abbu.90\n",
      "saurabhrekhasingh\n",
      "pulkit.sachdev\n",
      "vijeshwarbideshwar\n",
      "prraveengupta\n",
      "thapakji1\n",
      "theonevishalvray\n",
      "kitrokatmeo_\n",
      "himalyan_004\n",
      "fashion.house.clothing.shop\n",
      "a5h0kj\n",
      "geetika_popli\n",
      "bakefresh_delhi\n",
      "shiva.narayan.9803\n",
      "29himani\n",
      "nikita_chauhan09\n",
      "manjugupta8682\n",
      "shamshadalam810\n",
      "mr._negi_r\n",
      "naveenverma___\n",
      "anisha.bansal64\n",
      "life_reality_truth\n",
      "rajnish.singh.tomar\n",
      "shrutisinghal14\n",
      "sitans_9\n",
      "fashion_planet24\n",
      "mr.dada67\n",
      "tk_shaddy_\n",
      "anku2_2\n",
      "nashra98760\n",
      "___mrwow___\n",
      "anni.mahato\n",
      "ishitaarvindsharma\n",
      "sunitakhanna160\n",
      "iamanishyadav\n",
      "namityv\n",
      "swati.0507\n",
      "tanw.ar0007\n",
      "jazziey_pvt\n",
      "inviolate_akki\n",
      "vshippop.singh\n",
      "iamrajveersharma\n",
      "amitsingh2419922019\n",
      "ami_hnamte\n",
      "inkdefy\n",
      "niharikagarg07\n",
      "farbud.rezaee\n",
      "lucky_lens2310\n",
      "namanb512_\n",
      "wadhwa_raghav\n",
      "iammukesh700\n",
      "minal_gpta_\n",
      "globetrotters_fam\n",
      "parti5236\n",
      "sangeeta.pal\n",
      "peeeru1\n",
      "heerkhan.555\n",
      "bhavyasoni2129\n",
      "nehasaxena_5893\n",
      "adietya_kumar\n",
      "princy_balyan\n",
      "adhikaridipti\n",
      "jayant___13\n",
      "mannu_upadhyay__\n",
      "thesaurav_j\n",
      "shiningsim_13\n",
      "vegansumedha\n",
      "salonisethii12\n",
      "blackmangoindia\n",
      "sagararora1\n",
      "viiiivek_\n",
      "therishabhtalwar\n",
      "akash_vashishtha_\n",
      "xsmart_aniket_\n",
      "riya_malhotra050\n",
      "_vanshxbhatia_\n",
      "itz_payal06\n",
      "shrichrisna\n",
      "_ritu._.verma_\n",
      "pubalidutta29\n",
      "blessingshealingssolutions\n",
      "angelinaa.khan_\n",
      "_kr_naman_\n",
      "behove_behove___\n",
      "ashu._xvii\n",
      "cutandstyleofficial\n",
      "fade_hair_style\n",
      "quarantinedayss_2020\n",
      "shyamksaeh\n",
      "db_1995_\n",
      "shailaks\n",
      "mansibhajanka\n",
      "devesh.kumarr\n",
      "zryny70\n",
      "isunitakakkar\n",
      "jyotijolly\n",
      "abhinisharma\n",
      "madoversbrands2020\n",
      "archana.singh.7\n",
      "tilakraj9335\n",
      "rajanmehta123\n",
      "harsh_vardhan4484\n",
      "devkumar9617\n",
      "___.swati\n",
      "_anja__________\n",
      "guner.bh98\n",
      "saransh_yadav26\n",
      "bora_gxankar\n",
      "apurva.2413\n",
      "in_the_colour_wheel\n",
      "mudit.2000\n",
      "mannat.pvt._\n",
      "hhh.hh848\n",
      "soulfulkind\n",
      "food_n_wine_\n",
      "walia__shagun\n",
      "ananyaguglani\n",
      "kanishq_basoya_dellhii0001\n",
      "arun_sajwan26\n",
      "nitika_suneja\n",
      "quote.zon\n",
      "_aisha.ab_\n",
      "alt_kar95\n"
     ]
    }
   ],
   "source": [
    "# calling function for so delhi and printing the set\n",
    "\n",
    "So_Delhi_Followers = So_Delhi_followers('So Delhi')\n",
    "\n",
    "for i in So_Delhi_Followers :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2) Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "In this Question i have made a function which can take an argument to tell what to extract i.e followers or following.\n",
    "If , we want to extract Followers then pass \"my_followers\" and if want to extract following then passed \"my_following\"\n",
    "\n",
    "So, this function returns all the user names of the given user i.e your own followers or following .\n",
    "\n",
    "For this, i have first opened the profile of the user and then i have visited follower or following accordingly,\n",
    "then i have made an infinite loop to scroll till end so that all the elements gets loaded.\n",
    "then, extracted all the user names in the set \n",
    "\n",
    "Now, we have 3 sets \n",
    "1) having user names of foodtalkindia followers.\n",
    "2) my followers\n",
    "3) my following\n",
    "\n",
    "\"\"\"\"\"\n",
    "\n",
    "def all_user_names(a) : \n",
    "    driver.get('https://www.instagram.com/')\n",
    "    driver.find_element_by_class_name('gmFkV').click() # going to profile\n",
    "    time.sleep(3) \n",
    "    if a == 'my_following' : # checking followers or following\n",
    "        driver.find_elements_by_class_name('-nal3')[2].click()  \n",
    "    else :\n",
    "        driver.find_elements_by_class_name('-nal3')[1].click()\n",
    "\n",
    "    my_following = set()\n",
    "    my_followers = set()\n",
    "\n",
    "    # applying infine loop to scroll till the end so that all user names gets loaded.\n",
    "    \n",
    "    current_height = driver.execute_script('return document.getElementsByClassName(\"isgrP\")[0].scrollHeight;')\n",
    "\n",
    "    while True :\n",
    "        driver.execute_script('document.getElementsByClassName(\"isgrP\")[0].scrollTo(0, arguments[0]);', current_height)\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script('return document.getElementsByClassName(\"isgrP\")[0].scrollHeight;')\n",
    "        if new_height == current_height :\n",
    "            break\n",
    "        current_height = new_height\n",
    "\n",
    "    # Now, extracting user names only in the sets and returning the sets\n",
    "    \n",
    "    if a == 'my_following' : # checking condn\n",
    "        following = driver.find_elements_by_class_name('FPmhX') # extracting user name element\n",
    "\n",
    "        for i in following :\n",
    "            my_following.add(i.get_attribute('title'))\n",
    "\n",
    "        return my_following\n",
    "\n",
    "    else :\n",
    "        follower = driver.find_elements_by_class_name('FPmhX') # extracting user name element\n",
    "\n",
    "        for i in follower :\n",
    "            my_followers.add(i.get_attribute('title'))\n",
    "\n",
    "        return my_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'an.eloquence',\n",
       " 'ankurgoel20',\n",
       " 'arbaj_raza___',\n",
       " 'architchhillar',\n",
       " 'as_dancer1',\n",
       " 'chillbeeeofficial',\n",
       " 'concienciakrishna',\n",
       " 'indian_army_brand',\n",
       " 'keep_going192',\n",
       " 'piyushsharmass',\n",
       " 'platesofflavour929',\n",
       " 'priya_2020grover',\n",
       " 'pubgskin._seller',\n",
       " 's.k_royal_rana',\n",
       " 'star_sheen'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing my followers by calling function and passing string 'my_followers'\n",
    "\n",
    "my_followers = all_user_names('my_followers')\n",
    "my_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5mpixels.beauties',\n",
       " '_._nehha_._',\n",
       " '_.lustika._',\n",
       " '__.mystical__.dimple___',\n",
       " '_______jafrin',\n",
       " '_____sumiya',\n",
       " '___jennifer_elliot___',\n",
       " '__blossom_bee',\n",
       " '__indian_modeling__page_',\n",
       " '__kishan_parmar',\n",
       " '__shabnam_16__',\n",
       " '__vani_anand',\n",
       " '_aairaah_',\n",
       " '_angelic_dimples_',\n",
       " '_deactiveddddddddd',\n",
       " '_drops.of.melting.heart_',\n",
       " '_ell_22_',\n",
       " '_hkmlife',\n",
       " '_imapeksha__',\n",
       " '_kanikasehrawat_',\n",
       " '_sizzlings91_',\n",
       " '_skinniebabe',\n",
       " '_sweet.munchkin_',\n",
       " '_zowaira.prova_',\n",
       " 'a.paraet',\n",
       " 'aaavvv_bbbc',\n",
       " 'aanchalmathpal',\n",
       " 'aarushi5935',\n",
       " 'aasanhai008',\n",
       " 'acharya_prashant_english',\n",
       " 'acharya_prashant_hindi',\n",
       " 'aditis5262',\n",
       " 'ahana_rai_',\n",
       " 'aisha_sarin07',\n",
       " 'aivu__keya',\n",
       " 'akanshaavats',\n",
       " 'akhand_hindutva',\n",
       " 'akpandey___09',\n",
       " 'alex_amok',\n",
       " 'alizhan_bessmertnyi',\n",
       " 'allallgloriestoshrilaprabhupad',\n",
       " 'an_il9711',\n",
       " 'anam_ansari_._',\n",
       " 'angel.constii',\n",
       " 'angel_priyanka_rani',\n",
       " 'ankita.ar0ra',\n",
       " 'ankitankit828',\n",
       " 'annesha_alzarah_anha',\n",
       " 'anushka.garg.92798',\n",
       " 'anzy.entertainment',\n",
       " 'aqsa_sheikh305',\n",
       " 'asian_beauty_journal',\n",
       " 'aurpa_haider',\n",
       " 'ayesha_hossian_',\n",
       " 'ayuheartlove',\n",
       " 'ayushiroyyyyy',\n",
       " 'azizakinozmen',\n",
       " 'balkishandagar',\n",
       " 'bc.savitabhabhi',\n",
       " 'be.your.own.inspiration_',\n",
       " 'being_awishy',\n",
       " 'bhaarat.guru',\n",
       " 'bhagavadgitachanting',\n",
       " 'bhakta_justin',\n",
       " 'bijo_zukan',\n",
       " 'boronice19',\n",
       " 'brendanfludd',\n",
       " 'buiyaaahh',\n",
       " 'bzone_mishima',\n",
       " 'catching.trends',\n",
       " 'chanakyamotivation',\n",
       " 'chant_hare_krishna_be_happy',\n",
       " 'chhilwal_pinki',\n",
       " 'chicabonita.10',\n",
       " 'chikuwa123456123456',\n",
       " 'chill_munda',\n",
       " 'commondoveinsta',\n",
       " 'creazy_boy_dev',\n",
       " 'cutie.sush',\n",
       " 'cuty5219',\n",
       " 'daddyofdogs',\n",
       " 'daily_darsan',\n",
       " 'dance_is_peace',\n",
       " 'ddnational',\n",
       " 'delhiwholesalefashion',\n",
       " 'den_8769',\n",
       " 'devotionaltales',\n",
       " 'diva_xoxo_',\n",
       " 'dkinsane69',\n",
       " 'dr.apj_abdul_kalam__',\n",
       " 'ekjeev_yashika',\n",
       " 'ekkadamsafaltakiorr',\n",
       " 'enak1996',\n",
       " 'erica.warren299',\n",
       " 'euphoric_you',\n",
       " 'fashionfemme_ff',\n",
       " 'flickatbabyvine',\n",
       " 'freshpaperpdtfanpage',\n",
       " 'gamingshailpanshu.pubg',\n",
       " 'gau7731',\n",
       " 'gaurgopaldas',\n",
       " 'gavintyagi',\n",
       " 'geetakshri_stuti',\n",
       " 'getsetwild',\n",
       " 'girls_of_asia.official',\n",
       " 'girlsshoutout32',\n",
       " 'giva.co',\n",
       " 'gouravrajput7816',\n",
       " 'gur_pinder_',\n",
       " 'haaarunya',\n",
       " 'harekrsnatv_iskcondesiretree',\n",
       " 'hayowolige',\n",
       " 'hemlattadutta09',\n",
       " 'high_jatt',\n",
       " 'himanshuvermafitness',\n",
       " 'hinano_ayakawa',\n",
       " 'hindu_gurukul_',\n",
       " 'hinduhistory',\n",
       " 'hinduism_and_science',\n",
       " 'houmon.nyuyokukaigo_love',\n",
       " 'houstoniskcon',\n",
       " 'i_am_punitkataria',\n",
       " 'iam_ahmad_008',\n",
       " 'iamharshchhikara',\n",
       " 'iammarjs',\n",
       " 'iampawfect',\n",
       " 'ide_followers',\n",
       " 'imsatyajeet_',\n",
       " 'ina___035',\n",
       " 'indian_girl_2000',\n",
       " 'indianarmy.adgpi',\n",
       " 'indiannavy',\n",
       " 'insta.gramer_0567',\n",
       " 'ishahaquearpita',\n",
       " 'iskcon__juhu_mumbai',\n",
       " 'iskcon_punjabibagh',\n",
       " 'iskcon_world',\n",
       " 'iskconahmedabad',\n",
       " 'iskconchd',\n",
       " 'iskconinc',\n",
       " 'iskconkurukshetra',\n",
       " 'israt.khan_',\n",
       " 'itscamilataylorxoxo',\n",
       " 'itz_mohit_verma',\n",
       " 'ivy_410',\n",
       " 'jagannath.me',\n",
       " 'jaspreetkourr',\n",
       " 'jessica_bt_rodrigues',\n",
       " 'jivjaago',\n",
       " 'joanna.morgan34',\n",
       " 'kabirkhan2863',\n",
       " 'kanaiya__morlivala',\n",
       " 'kattar.__.hindu',\n",
       " 'kaushik_reetika',\n",
       " 'kazianikaa',\n",
       " 'keep_going192',\n",
       " 'kensanitrvg',\n",
       " 'khanna_siddhi',\n",
       " 'khemraj.01',\n",
       " 'kj_life_stories',\n",
       " 'knowledge_of_bhagavad_gita',\n",
       " 'komalmusicbox',\n",
       " 'komalv_',\n",
       " 'kriitikaamehra',\n",
       " 'krishna.paramathma',\n",
       " 'krishpal_vishnoi',\n",
       " 'l12comedy',\n",
       " 'lamiarei',\n",
       " 'laughingcolours',\n",
       " 'lesbian1919tokyo',\n",
       " 'lesbo_69____',\n",
       " 'lilsian1',\n",
       " 'little__princess_11',\n",
       " 'll_bhanu_tak_ll',\n",
       " 'looh_beats',\n",
       " 'lord_of_love_kanha',\n",
       " 'lordkrishna__',\n",
       " 'losttemples_276',\n",
       " 'luv_ahan',\n",
       " 'm.hakase',\n",
       " 'madhur_tyagii',\n",
       " 'mahabharat_fans_page',\n",
       " 'mahabharat_universe',\n",
       " 'mahabhartha',\n",
       " 'mahiii___mahii',\n",
       " 'marquistrill__',\n",
       " 'maurellous',\n",
       " 'mdua3357',\n",
       " 'ministryofculturegoi',\n",
       " 'missbrooke_lyn',\n",
       " 'mitoumio',\n",
       " 'miyakosono_official',\n",
       " 'modanasya',\n",
       " 'mohini_malhar',\n",
       " 'mohsin__bhatt',\n",
       " 'motivation_line_',\n",
       " 'mrs.argyros_',\n",
       " 'mujietao96431',\n",
       " 'mulay_shruti',\n",
       " 'mym_official_backup',\n",
       " 'nanny_babygirl26',\n",
       " 'naveeen.saini',\n",
       " 'neerajsaket6',\n",
       " 'neha_jain_00010',\n",
       " 'niasra_o3',\n",
       " 'nickita_singh',\n",
       " 'nieon_0_',\n",
       " 'nierxiaoyao',\n",
       " 'nikhil_hooda05',\n",
       " 'noddy1231',\n",
       " 'nor_l1d4h',\n",
       " 'notealolona',\n",
       " 'nupur_vaash',\n",
       " 'official_psymi',\n",
       " 'only.haryanvi',\n",
       " 'paragpanwar',\n",
       " 'pari.rajput.__',\n",
       " 'pavinayagie_fc',\n",
       " 'pihugoel.7',\n",
       " 'pm_motivation_',\n",
       " 'pmmodi2024',\n",
       " 'pooji2728',\n",
       " 'popandshorn2',\n",
       " 'positive__reminders_',\n",
       " 'prachy__',\n",
       " 'prarthna_asr',\n",
       " 'prita.70',\n",
       " 'priyakshiiii_',\n",
       " 'propose.tomakomai',\n",
       " 'r.harshdeep',\n",
       " 'raam.bhaktt',\n",
       " 'radha_raman9',\n",
       " 'rahul.dahiya872018',\n",
       " 'rajat2013sharma',\n",
       " 'rakeshyadav3945',\n",
       " 'rakhi2154',\n",
       " 'raman__jangid',\n",
       " 'raodimpal_rdx',\n",
       " 'rathodvisuraj8',\n",
       " 'raymali73',\n",
       " 'reenaravinahlawat1911',\n",
       " 'renamatui27',\n",
       " 'rinipam',\n",
       " 'riya_talwar863',\n",
       " 'riyaroy6990',\n",
       " 'roadto2022en',\n",
       " 'rose_goldbarbie',\n",
       " 'rup_shera_143',\n",
       " 'sahabat.naikin.followers',\n",
       " 'saira.verma',\n",
       " 'sakshisinghal0824',\n",
       " 'salvia_ananna',\n",
       " 'samiksha_saini_111',\n",
       " 'sanaatanee',\n",
       " 'sanjayjalodia',\n",
       " 'sanjeevsehwag',\n",
       " 'sanjidaaababyy',\n",
       " 'saurav__singh_rajput',\n",
       " 'school_of_vedic_science',\n",
       " 'seoulstreetstudios',\n",
       " 'sharonnnnnn.___',\n",
       " 'shivamsp95995',\n",
       " 'shivani.choudhary__',\n",
       " 'shivani_mishra326',\n",
       " 'shivani_mishra71',\n",
       " 'shivi12_',\n",
       " 'shivu_18ss',\n",
       " 'shraddhuuu143',\n",
       " 'siddiquisubhani',\n",
       " 'simplyripped.ig',\n",
       " 'simranbarolia',\n",
       " 'singers.promotions',\n",
       " 'singhkajal39',\n",
       " 'sith771',\n",
       " 'skybeatsindia',\n",
       " 'snehashrivastav_',\n",
       " 'son_of_bharat.maa',\n",
       " 'sonalbohra99',\n",
       " 'sourabhraaj.jain',\n",
       " 'star_sheen',\n",
       " 'sudhir_chaudharyfans',\n",
       " 'sunny_rana_',\n",
       " 'suzyengxoxo',\n",
       " 'swaamiramdev',\n",
       " 'swara_2412_',\n",
       " 'swatantra_singh_sansanwal',\n",
       " 'swatsin07',\n",
       " 'sweet_dairies089',\n",
       " 't1smile',\n",
       " 'tahiatabassum138',\n",
       " 'talks_of_bharat',\n",
       " 'tanha_fiza',\n",
       " 'tanu.verma1925',\n",
       " 'telugubrowngirl',\n",
       " 'terracesmine_',\n",
       " 'that_perfectlyimperfect_anki',\n",
       " 'the.ami.zou',\n",
       " 'the_best_motivation_14',\n",
       " 'thedailymemoirr',\n",
       " 'theshowoffshots',\n",
       " 'thisismybharat',\n",
       " 'tiny_tomatoes',\n",
       " 'toomi_nico',\n",
       " 'trishu_.love',\n",
       " 'tsm.ent_jonathan',\n",
       " 'ui__ux',\n",
       " 'umme.usha',\n",
       " 'united.fitness_ig',\n",
       " 'vaginasource',\n",
       " 'vaishali_16sharma',\n",
       " 'vaishnavi__shekhawat',\n",
       " 'vampiire_diarries',\n",
       " 'vandip_ahir_ooffical',\n",
       " 'vasudev.krishna_updesh',\n",
       " 'vedicmaths2020',\n",
       " 'vedictales',\n",
       " 'vi.0011',\n",
       " 'vinaykandhal.007',\n",
       " 'vishaal_gulia',\n",
       " 'vishal_singh2012',\n",
       " 'vivek_bindra',\n",
       " 'vrindavan_monk',\n",
       " 'wallakarl',\n",
       " 'waseemamrohi_1life',\n",
       " 'xoxo_avniiii',\n",
       " 'yogifitlove',\n",
       " 'yogita.birhman',\n",
       " 'yoosulah3737',\n",
       " 'zarin_salsabil',\n",
       " 'zarinava_'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing my following by calling function and passing string 'my_following'\n",
    "\n",
    "my_following = all_user_names('my_following')\n",
    "my_following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5mpixels.beauties',\n",
       " '_._nehha_._',\n",
       " '_.lustika._',\n",
       " '__.mystical__.dimple___',\n",
       " '_______jafrin',\n",
       " '_____sumiya',\n",
       " '___jennifer_elliot___',\n",
       " '__blossom_bee',\n",
       " '__indian_modeling__page_',\n",
       " '__kishan_parmar',\n",
       " '__shabnam_16__',\n",
       " '__vani_anand',\n",
       " '_aairaah_',\n",
       " '_angelic_dimples_',\n",
       " '_deactiveddddddddd',\n",
       " '_drops.of.melting.heart_',\n",
       " '_ell_22_',\n",
       " '_hkmlife',\n",
       " '_imapeksha__',\n",
       " '_kanikasehrawat_',\n",
       " '_sizzlings91_',\n",
       " '_skinniebabe',\n",
       " '_sweet.munchkin_',\n",
       " '_zowaira.prova_',\n",
       " 'a.paraet',\n",
       " 'aaavvv_bbbc',\n",
       " 'aanchalmathpal',\n",
       " 'aarushi5935',\n",
       " 'aasanhai008',\n",
       " 'acharya_prashant_english',\n",
       " 'acharya_prashant_hindi',\n",
       " 'aditis5262',\n",
       " 'ahana_rai_',\n",
       " 'aisha_sarin07',\n",
       " 'aivu__keya',\n",
       " 'akanshaavats',\n",
       " 'akhand_hindutva',\n",
       " 'akpandey___09',\n",
       " 'alex_amok',\n",
       " 'alizhan_bessmertnyi',\n",
       " 'allallgloriestoshrilaprabhupad',\n",
       " 'an_il9711',\n",
       " 'anam_ansari_._',\n",
       " 'angel.constii',\n",
       " 'angel_priyanka_rani',\n",
       " 'ankita.ar0ra',\n",
       " 'ankitankit828',\n",
       " 'annesha_alzarah_anha',\n",
       " 'anushka.garg.92798',\n",
       " 'anzy.entertainment',\n",
       " 'aqsa_sheikh305',\n",
       " 'asian_beauty_journal',\n",
       " 'aurpa_haider',\n",
       " 'ayesha_hossian_',\n",
       " 'ayuheartlove',\n",
       " 'ayushiroyyyyy',\n",
       " 'azizakinozmen',\n",
       " 'balkishandagar',\n",
       " 'bc.savitabhabhi',\n",
       " 'be.your.own.inspiration_',\n",
       " 'being_awishy',\n",
       " 'bhaarat.guru',\n",
       " 'bhagavadgitachanting',\n",
       " 'bhakta_justin',\n",
       " 'bijo_zukan',\n",
       " 'boronice19',\n",
       " 'brendanfludd',\n",
       " 'buiyaaahh',\n",
       " 'bzone_mishima',\n",
       " 'catching.trends',\n",
       " 'chanakyamotivation',\n",
       " 'chant_hare_krishna_be_happy',\n",
       " 'chhilwal_pinki',\n",
       " 'chicabonita.10',\n",
       " 'chikuwa123456123456',\n",
       " 'chill_munda',\n",
       " 'commondoveinsta',\n",
       " 'creazy_boy_dev',\n",
       " 'cutie.sush',\n",
       " 'cuty5219',\n",
       " 'daddyofdogs',\n",
       " 'daily_darsan',\n",
       " 'dance_is_peace',\n",
       " 'ddnational',\n",
       " 'delhiwholesalefashion',\n",
       " 'den_8769',\n",
       " 'devotionaltales',\n",
       " 'diva_xoxo_',\n",
       " 'dkinsane69',\n",
       " 'dr.apj_abdul_kalam__',\n",
       " 'ekjeev_yashika',\n",
       " 'ekkadamsafaltakiorr',\n",
       " 'enak1996',\n",
       " 'erica.warren299',\n",
       " 'euphoric_you',\n",
       " 'fashionfemme_ff',\n",
       " 'flickatbabyvine',\n",
       " 'freshpaperpdtfanpage',\n",
       " 'gamingshailpanshu.pubg',\n",
       " 'gau7731',\n",
       " 'gaurgopaldas',\n",
       " 'gavintyagi',\n",
       " 'geetakshri_stuti',\n",
       " 'getsetwild',\n",
       " 'girls_of_asia.official',\n",
       " 'girlsshoutout32',\n",
       " 'giva.co',\n",
       " 'gouravrajput7816',\n",
       " 'gur_pinder_',\n",
       " 'haaarunya',\n",
       " 'harekrsnatv_iskcondesiretree',\n",
       " 'hayowolige',\n",
       " 'hemlattadutta09',\n",
       " 'high_jatt',\n",
       " 'himanshuvermafitness',\n",
       " 'hinano_ayakawa',\n",
       " 'hindu_gurukul_',\n",
       " 'hinduhistory',\n",
       " 'hinduism_and_science',\n",
       " 'houmon.nyuyokukaigo_love',\n",
       " 'houstoniskcon',\n",
       " 'i_am_punitkataria',\n",
       " 'iam_ahmad_008',\n",
       " 'iamharshchhikara',\n",
       " 'iammarjs',\n",
       " 'iampawfect',\n",
       " 'ide_followers',\n",
       " 'imsatyajeet_',\n",
       " 'ina___035',\n",
       " 'indian_girl_2000',\n",
       " 'indianarmy.adgpi',\n",
       " 'indiannavy',\n",
       " 'insta.gramer_0567',\n",
       " 'ishahaquearpita',\n",
       " 'iskcon__juhu_mumbai',\n",
       " 'iskcon_punjabibagh',\n",
       " 'iskcon_world',\n",
       " 'iskconahmedabad',\n",
       " 'iskconchd',\n",
       " 'iskconinc',\n",
       " 'iskconkurukshetra',\n",
       " 'israt.khan_',\n",
       " 'itscamilataylorxoxo',\n",
       " 'itz_mohit_verma',\n",
       " 'ivy_410',\n",
       " 'jagannath.me',\n",
       " 'jaspreetkourr',\n",
       " 'jessica_bt_rodrigues',\n",
       " 'jivjaago',\n",
       " 'joanna.morgan34',\n",
       " 'kabirkhan2863',\n",
       " 'kanaiya__morlivala',\n",
       " 'kattar.__.hindu',\n",
       " 'kaushik_reetika',\n",
       " 'kazianikaa',\n",
       " 'kensanitrvg',\n",
       " 'khanna_siddhi',\n",
       " 'khemraj.01',\n",
       " 'kj_life_stories',\n",
       " 'knowledge_of_bhagavad_gita',\n",
       " 'komalmusicbox',\n",
       " 'komalv_',\n",
       " 'kriitikaamehra',\n",
       " 'krishna.paramathma',\n",
       " 'krishpal_vishnoi',\n",
       " 'l12comedy',\n",
       " 'lamiarei',\n",
       " 'laughingcolours',\n",
       " 'lesbian1919tokyo',\n",
       " 'lesbo_69____',\n",
       " 'lilsian1',\n",
       " 'little__princess_11',\n",
       " 'll_bhanu_tak_ll',\n",
       " 'looh_beats',\n",
       " 'lord_of_love_kanha',\n",
       " 'lordkrishna__',\n",
       " 'losttemples_276',\n",
       " 'luv_ahan',\n",
       " 'm.hakase',\n",
       " 'madhur_tyagii',\n",
       " 'mahabharat_fans_page',\n",
       " 'mahabharat_universe',\n",
       " 'mahabhartha',\n",
       " 'mahiii___mahii',\n",
       " 'marquistrill__',\n",
       " 'maurellous',\n",
       " 'mdua3357',\n",
       " 'ministryofculturegoi',\n",
       " 'missbrooke_lyn',\n",
       " 'mitoumio',\n",
       " 'miyakosono_official',\n",
       " 'modanasya',\n",
       " 'mohini_malhar',\n",
       " 'mohsin__bhatt',\n",
       " 'motivation_line_',\n",
       " 'mrs.argyros_',\n",
       " 'mujietao96431',\n",
       " 'mulay_shruti',\n",
       " 'mym_official_backup',\n",
       " 'nanny_babygirl26',\n",
       " 'naveeen.saini',\n",
       " 'neerajsaket6',\n",
       " 'neha_jain_00010',\n",
       " 'niasra_o3',\n",
       " 'nickita_singh',\n",
       " 'nieon_0_',\n",
       " 'nierxiaoyao',\n",
       " 'nikhil_hooda05',\n",
       " 'noddy1231',\n",
       " 'nor_l1d4h',\n",
       " 'notealolona',\n",
       " 'nupur_vaash',\n",
       " 'official_psymi',\n",
       " 'only.haryanvi',\n",
       " 'paragpanwar',\n",
       " 'pari.rajput.__',\n",
       " 'pavinayagie_fc',\n",
       " 'pihugoel.7',\n",
       " 'pm_motivation_',\n",
       " 'pmmodi2024',\n",
       " 'pooji2728',\n",
       " 'popandshorn2',\n",
       " 'positive__reminders_',\n",
       " 'prachy__',\n",
       " 'prarthna_asr',\n",
       " 'prita.70',\n",
       " 'priyakshiiii_',\n",
       " 'propose.tomakomai',\n",
       " 'r.harshdeep',\n",
       " 'raam.bhaktt',\n",
       " 'radha_raman9',\n",
       " 'rahul.dahiya872018',\n",
       " 'rajat2013sharma',\n",
       " 'rakeshyadav3945',\n",
       " 'rakhi2154',\n",
       " 'raman__jangid',\n",
       " 'raodimpal_rdx',\n",
       " 'rathodvisuraj8',\n",
       " 'raymali73',\n",
       " 'reenaravinahlawat1911',\n",
       " 'renamatui27',\n",
       " 'rinipam',\n",
       " 'riya_talwar863',\n",
       " 'riyaroy6990',\n",
       " 'roadto2022en',\n",
       " 'rose_goldbarbie',\n",
       " 'rup_shera_143',\n",
       " 'sahabat.naikin.followers',\n",
       " 'saira.verma',\n",
       " 'sakshisinghal0824',\n",
       " 'salvia_ananna',\n",
       " 'samiksha_saini_111',\n",
       " 'sanaatanee',\n",
       " 'sanjayjalodia',\n",
       " 'sanjeevsehwag',\n",
       " 'sanjidaaababyy',\n",
       " 'saurav__singh_rajput',\n",
       " 'school_of_vedic_science',\n",
       " 'seoulstreetstudios',\n",
       " 'sharonnnnnn.___',\n",
       " 'shivamsp95995',\n",
       " 'shivani.choudhary__',\n",
       " 'shivani_mishra326',\n",
       " 'shivani_mishra71',\n",
       " 'shivi12_',\n",
       " 'shivu_18ss',\n",
       " 'shraddhuuu143',\n",
       " 'siddiquisubhani',\n",
       " 'simplyripped.ig',\n",
       " 'simranbarolia',\n",
       " 'singers.promotions',\n",
       " 'singhkajal39',\n",
       " 'sith771',\n",
       " 'skybeatsindia',\n",
       " 'snehashrivastav_',\n",
       " 'son_of_bharat.maa',\n",
       " 'sonalbohra99',\n",
       " 'sourabhraaj.jain',\n",
       " 'sudhir_chaudharyfans',\n",
       " 'sunny_rana_',\n",
       " 'suzyengxoxo',\n",
       " 'swaamiramdev',\n",
       " 'swara_2412_',\n",
       " 'swatantra_singh_sansanwal',\n",
       " 'swatsin07',\n",
       " 'sweet_dairies089',\n",
       " 't1smile',\n",
       " 'tahiatabassum138',\n",
       " 'talks_of_bharat',\n",
       " 'tanha_fiza',\n",
       " 'tanu.verma1925',\n",
       " 'telugubrowngirl',\n",
       " 'terracesmine_',\n",
       " 'that_perfectlyimperfect_anki',\n",
       " 'the.ami.zou',\n",
       " 'the_best_motivation_14',\n",
       " 'thedailymemoirr',\n",
       " 'theshowoffshots',\n",
       " 'thisismybharat',\n",
       " 'tiny_tomatoes',\n",
       " 'toomi_nico',\n",
       " 'trishu_.love',\n",
       " 'tsm.ent_jonathan',\n",
       " 'ui__ux',\n",
       " 'umme.usha',\n",
       " 'united.fitness_ig',\n",
       " 'vaginasource',\n",
       " 'vaishali_16sharma',\n",
       " 'vaishnavi__shekhawat',\n",
       " 'vampiire_diarries',\n",
       " 'vandip_ahir_ooffical',\n",
       " 'vasudev.krishna_updesh',\n",
       " 'vedicmaths2020',\n",
       " 'vedictales',\n",
       " 'vi.0011',\n",
       " 'vinaykandhal.007',\n",
       " 'vishaal_gulia',\n",
       " 'vishal_singh2012',\n",
       " 'vivek_bindra',\n",
       " 'vrindavan_monk',\n",
       " 'wallakarl',\n",
       " 'waseemamrohi_1life',\n",
       " 'xoxo_avniiii',\n",
       " 'yogifitlove',\n",
       " 'yogita.birhman',\n",
       " 'yoosulah3737',\n",
       " 'zarin_salsabil',\n",
       " 'zarinava_'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting only those user names whom i am following but they aren't following me back\n",
    "# so following - followers\n",
    "\n",
    "Not_following_me = my_following - my_followers\n",
    "Not_following_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting those user names whor are the followers of “foodtalkindia” that you are following but those who don’t follow you.\n",
    "# so finding intersection\n",
    "\n",
    "answer_user_names = Not_following_me.intersection(Food_Talk_India_Followers)\n",
    "answer_user_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Check the story of ‘coding.ninjas’. Consider the following Scenarios and print error messages accordingly -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1) If You have already seen the story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2) Or The user has no story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3) Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"\"\n",
    "Created fiunction that visits the given page then it checks for presence of element which is present only if story is uploaded.\n",
    "if user has no story then it will give TimeoutError and i have used try except blocks to handle this\n",
    "\n",
    "If story is present then to check if it's seen or not then it is checked by the height of the icon or button which on pressing\n",
    "opens the story\n",
    "\n",
    "If it is 210 means story is not seen yet so we clicks on it and watch the story \n",
    "and if not then we prints msg for same .\n",
    "\n",
    "\"\"\"\"\"\n",
    "def story_check(profile) :\n",
    "    driver.get('https://www.instagram.com/')\n",
    "    open_profile(profile) # calling function to open given page\n",
    "    time.sleep(2)\n",
    "    print(\"checking coding ninja's story status\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        wait = WebDriverWait(driver, 7)\n",
    "        a = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'h5uC0'))) #if user has no story then it will give TimeoutException\n",
    "        height = driver.find_element_by_class_name(\"CfWVH\").get_attribute('height') # finding height of button\n",
    "        if int(height) == 208:\n",
    "            print(\"Already seen the Story.\")\n",
    "        else:\n",
    "            a = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'_2dbep')))   #for story check button\n",
    "            a.click() # clicking on button\n",
    "            print(\"Seeing the story\")\n",
    "            \n",
    "    except TimeoutException: # handling exception\n",
    "\n",
    "        print(\"no story uploaded\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking coding ninja's story status\n",
      "Seeing the story\n"
     ]
    }
   ],
   "source": [
    "# chekcing story on coding.ninjas page\n",
    "\n",
    "story_check('coding.ninjas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
